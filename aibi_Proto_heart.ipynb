{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc766d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.14.1\n",
      "Eager execution enabled:  False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(40) # suppress deprecation messages\n",
    "tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs\n",
    "from alibi.explainers import CounterfactualProto\n",
    "\n",
    "\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088e792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "def set_seed(s=0):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)\n",
    "\n",
    "df = pd.read_csv('E://Graduation_Project//datasets//heart.csv')\n",
    "\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "numeric_features = [col for col in df.columns if col not in categorical_features + ['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "from dice_ml.utils.helpers import DataTransfomer\n",
    "from sklearn.model_selection import train_test_split\n",
    "transformer = DataTransfomer(func='ohe-min-max')\n",
    "\n",
    "target = df['target']\n",
    "train_dataset, test_dataset, y_train, y_test = train_test_split(df, \n",
    "                                                                target,\n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=42, \n",
    "                                                                stratify=df['target'])\n",
    "\n",
    "\n",
    "X_train_df = train_dataset.drop('target', axis=1)\n",
    "X_test_df = test_dataset.drop('target', axis=1)\n",
    "d = dice_ml.Data(dataframe=df,\n",
    "                 continuous_features=numeric_features,\n",
    "                 outcome_name='target')\n",
    "\n",
    "transformer.feed_data_params(d)\n",
    "\n",
    "transformer.initialize_transform_func()\n",
    "\n",
    "X_train = transformer.transform(X_train_df)\n",
    "X_test = transformer.transform(X_test_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8165074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def build_simple_dnn():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(16, activation='relu', input_shape=(31,)))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_simple_dnn()\n",
    "model.load_weights('my_model_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1) Perform OHE + MinMax on the independent variables, and generate ohe_encoded_feature_names accordingly\n",
    "X = d.data_df.drop(columns=[d.outcome_name])\n",
    "ohe_norm_df = d.get_ohe_min_max_normalized_data(X)\n",
    "d.create_ohe_params(one_hot_encoded_data=ohe_norm_df)\n",
    "\n",
    "ohe_cols = list(d.ohe_encoded_feature_names)\n",
    "\n",
    "# 3) Calculate the column index groups for each \"categorical feature\" in the OHE matrix\n",
    "#    PublicData already provides this function (returns a list[list[int]], order matches categorical_feature_names)\n",
    "cat_index_groups = d.get_encoded_categorical_feature_indexes()\n",
    "\n",
    "# 4) Calculate the size (expanded dimension) of each categorical feature\n",
    "cat_sizes = [len(g) for g in cat_index_groups]\n",
    "\n",
    "# 5) Calculate the starting column index for each categorical feature after OHE:\n",
    "#    Note: In PublicData, the column order is: all continuous feature columns first, then OHE columns for each categorical feature in order.\n",
    "#    Therefore, the starting index can be obtained by \"number of continuous features + cumulative dimensions of previous categorical features\"; or simply by min(index) of each group.\n",
    "num_numeric = len(numeric_features)\n",
    "cat_start_indices_by_cumsum = np.cumsum([num_numeric] + cat_sizes[:-1]) if len(cat_sizes) > 0 else np.array([])\n",
    "cat_start_indices_by_min = np.array([min(g) for g in cat_index_groups]) if len(cat_index_groups) > 0 else np.array([])\n",
    "\n",
    "# Both methods should be consistent (if needed, you can assert)\n",
    "# assert np.all(cat_start_indices_by_cumsum == cat_start_indices_by_min)\n",
    "\n",
    "# 6) Build a dictionary {start index: dimension} (equivalent to your approach with OneHotEncoder)\n",
    "cat_vars_ohe = {int(start): int(size) for start, size in zip(cat_start_indices_by_min, cat_sizes)}\n",
    "\n",
    "print(\"Column names after OHE:\", ohe_cols)\n",
    "print(\"Continuous features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"OHE dimension for each categorical feature cat_sizes:\", cat_sizes)\n",
    "print(\"Starting index for each categorical feature (obtained by min):\", cat_start_indices_by_min.tolist())\n",
    "print(\"Start index to dimension mapping cat_vars_ohe:\", cat_vars_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be65776",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test.iloc[[22]].to_numpy(dtype=float)\n",
    "shape = X.shape\n",
    "beta = 0.5\n",
    "c_init = 1\n",
    "c_steps = 5\n",
    "max_iterations = 500\n",
    "rng = (0, 1.)  # scale features between -1 and 1\n",
    "rng_shape = (1,) + X_train_df.shape[1:]\n",
    "feature_range = ((np.ones(rng_shape) * rng[0]).astype(np.float32),\n",
    "                 (np.ones(rng_shape) * rng[1]).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d32912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "No encoder specified. Using k-d trees to represent class prototypes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CounterfactualProto(meta={\n",
       "  'name': 'CounterfactualProto',\n",
       "  'type': ['blackbox', 'tensorflow', 'keras'],\n",
       "  'explanations': ['local'],\n",
       "  'params': {\n",
       "              'kappa': 0.0,\n",
       "              'beta': 0.5,\n",
       "              'gamma': 0.0,\n",
       "              'theta': 0.0,\n",
       "              'cat_vars': {\n",
       "                            5: 2,\n",
       "                            7: 5,\n",
       "                            12: 2,\n",
       "                            14: 3,\n",
       "                            17: 2,\n",
       "                            19: 3,\n",
       "                            22: 4,\n",
       "                            26: 5}\n",
       "                          ,\n",
       "              'ohe': True,\n",
       "              'use_kdtree': True,\n",
       "              'learning_rate_init': 0.01,\n",
       "              'max_iterations': 500,\n",
       "              'c_init': 1,\n",
       "              'c_steps': 5,\n",
       "              'eps': (0.001, 0.001),\n",
       "              'clip': (-1000.0, 1000.0),\n",
       "              'update_num_grad': 1,\n",
       "              'write_dir': None,\n",
       "              'feature_range': (array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32), array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "      dtype=float32)),\n",
       "              'shape': (1, 31),\n",
       "              'is_model': True,\n",
       "              'is_ae': False,\n",
       "              'is_enc': False,\n",
       "              'enc_or_kdtree': True,\n",
       "              'is_cat': True,\n",
       "              'trustscore_kwargs': None,\n",
       "              'd_type': 'mvdm',\n",
       "              'w': None,\n",
       "              'disc_perc': (25, 50, 75),\n",
       "              'standardize_cat_vars': False,\n",
       "              'smooth': 1.0,\n",
       "              'center': True,\n",
       "              'update_feature_range': True}\n",
       "            ,\n",
       "  'version': '0.9.6'}\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cf = CounterfactualProto(model,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         use_kdtree=True,\n",
    "                         ohe=True,  # OHE flag\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps\n",
    "                        )\n",
    "cf.fit(X_train.to_numpy(), d_type='mvdm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f12167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex cp  trestbps   chol fbs restecg  thalach exang  oldpeak slope ca  \\\n",
       "0  46.0   1  3     150.0  231.0   0       0    147.0     0      3.6     2  0   \n",
       "\n",
       "     thal  \n",
       "0  normal  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation = cf.explain(X)\n",
    "X_df = pd.DataFrame(X, columns=d.ohe_encoded_feature_names)\n",
    "transformer.inverse_transform(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9703106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>150.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex cp  trestbps   chol fbs restecg  thalach exang  oldpeak slope ca  \\\n",
       "0  46.0   0  2     150.0  231.0   0       2    141.0     0      6.2     2  1   \n",
       "\n",
       "  thal  \n",
       "0    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cf_ohe_df = pd.DataFrame(explanation.cf['X'], columns=d.ohe_encoded_feature_names)\n",
    "transformer.inverse_transform(cf_ohe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04dc245e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7423ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Counterfactual of Index 0 had been generated\n",
      "The Counterfactual of Index 1 had been generated\n",
      "The Counterfactual of Index 2 had been generated\n",
      "The Counterfactual of Index 3 had been generated\n",
      "The Counterfactual of Index 4 had been generated\n",
      "The Counterfactual of Index 5 had been generated\n",
      "The Counterfactual of Index 6 had been generated\n",
      "The Counterfactual of Index 7 had been generated\n",
      "The Counterfactual of Index 8 had been generated\n",
      "The Counterfactual of Index 9 had been generated\n",
      "The Counterfactual of Index 10 had been generated\n",
      "The Counterfactual of Index 11 had been generated\n",
      "The Counterfactual of Index 12 had been generated\n",
      "The Counterfactual of Index 13 had been generated\n",
      "The Counterfactual of Index 14 had been generated\n",
      "The Counterfactual of Index 15 had been generated\n",
      "The Counterfactual of Index 16 had been generated\n",
      "The Counterfactual of Index 17 had been generated\n",
      "The Counterfactual of Index 18 had been generated\n",
      "The Counterfactual of Index 19 had been generated\n",
      "The Counterfactual of Index 20 had been generated\n",
      "The Counterfactual of Index 21 had been generated\n",
      "The Counterfactual of Index 22 had been generated\n",
      "The Counterfactual of Index 23 had been generated\n",
      "The Counterfactual of Index 24 had been generated\n",
      "The Counterfactual of Index 25 had been generated\n",
      "The Counterfactual of Index 26 had been generated\n",
      "The Counterfactual of Index 27 had been generated\n",
      "The Counterfactual of Index 28 had been generated\n",
      "The Counterfactual of Index 29 had been generated\n",
      "The Counterfactual of Index 30 had been generated\n",
      "The Counterfactual of Index 31 had been generated\n",
      "The Counterfactual of Index 32 had been generated\n",
      "The Counterfactual of Index 33 had been generated\n",
      "The Counterfactual of Index 34 had been generated\n",
      "The Counterfactual of Index 35 had been generated\n",
      "The Counterfactual of Index 36 had been generated\n",
      "The Counterfactual of Index 37 had been generated\n",
      "The Counterfactual of Index 38 had been generated\n",
      "The Counterfactual of Index 39 had been generated\n",
      "The Counterfactual of Index 40 had been generated\n",
      "The Counterfactual of Index 41 had been generated\n",
      "The Counterfactual of Index 42 had been generated\n",
      "The Counterfactual of Index 43 had been generated\n",
      "The Counterfactual of Index 44 had been generated\n",
      "The Counterfactual of Index 45 had been generated\n",
      "The Counterfactual of Index 46 had been generated\n",
      "The Counterfactual of Index 47 had been generated\n",
      "The Counterfactual of Index 48 had been generated\n",
      "The Counterfactual of Index 49 had been generated\n",
      "The Counterfactual of Index 50 had been generated\n",
      "The Counterfactual of Index 51 had been generated\n",
      "The Counterfactual of Index 52 had been generated\n",
      "The Counterfactual of Index 53 had been generated\n",
      "The Counterfactual of Index 54 had been generated\n",
      "The Counterfactual of Index 55 had been generated\n",
      "The Counterfactual of Index 56 had been generated\n",
      "The Counterfactual of Index 57 had been generated\n",
      "The Counterfactual of Index 58 had been generated\n",
      "The Counterfactual of Index 59 had been generated\n",
      "The Counterfactual of Index 60 had been generated\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cfs = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i, X_test_i in enumerate(X_test.to_numpy()):\n",
    "    explanation = cf.explain(X_test_i.reshape(1, -1))\n",
    "    X_df = pd.DataFrame(X_test_i.reshape(1, -1), columns=d.ohe_encoded_feature_names)\n",
    "    cf_ohe_df = pd.DataFrame(explanation.cf['X'], columns=d.ohe_encoded_feature_names)\n",
    "    orig_pd = transformer.inverse_transform(X_df)\n",
    "    cf_pd = transformer.inverse_transform(cf_ohe_df)\n",
    "    cfs.append((\n",
    "        orig_pd, cf_pd\n",
    "    ))\n",
    "    print(f\"The Counterfactual of Index {i} had been generated\")\n",
    "end = time.time()\n",
    "\n",
    "time_Alibi_proto = (end - start)/X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb2e0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import XAI_metrics   # 先 import 一次\n",
    "importlib.reload(XAI_metrics)  # 🔄 重新加载，不需要重启内核\n",
    "\n",
    "from XAI_metrics import calc_valid, calc_sparsity, calc_continuous_proximity, \\\n",
    "    calc_categorical_proximity, calc_manifold_distance, calc_cf_num\n",
    "\n",
    "\n",
    "valid_alibi_proto = calc_valid(cfs, model, transformer, df.shape[1])\n",
    "sparsity_alibi_proto = calc_sparsity(cfs, categorical_features)\n",
    "con_proximity_alibi_proto = calc_continuous_proximity(cfs, numeric_features)\n",
    "cat_proximity_alibi_proto = calc_categorical_proximity(cfs, categorical_features)\n",
    "manifold_alibi_proto = calc_manifold_distance(cfs, df, categorical_features)\n",
    "cf_num_alibi_proto = calc_cf_num(cfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66b23f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age sex cp  trestbps   chol fbs restecg  thalach exang  oldpeak slope ca  \\\n",
      "0  54.0   1  4     140.0  239.0   0       0    160.0     0      1.2     1  0   \n",
      "\n",
      "     thal  \n",
      "0  normal  \n",
      "    age sex cp  trestbps   chol fbs restecg  thalach exang  oldpeak slope ca  \\\n",
      "0  54.0   0  2     140.0  239.0   0       2    136.0     0      6.2     2  1   \n",
      "\n",
      "  thal  \n",
      "0    1  \n"
     ]
    }
   ],
   "source": [
    "X = X_train.iloc[[84]].to_numpy(dtype=float)\n",
    "explanation = cf.explain(X)\n",
    "X_df = pd.DataFrame(X, columns=d.ohe_encoded_feature_names)\n",
    "cf_ohe_df = pd.DataFrame(explanation.cf['X'], columns=d.ohe_encoded_feature_names)\n",
    "orig_pd = transformer.inverse_transform(X_df)\n",
    "cf_pd = transformer.inverse_transform(cf_ohe_df)\n",
    "print(orig_pd)\n",
    "print(cf_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dd4a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_alibi_proto = {\n",
    "    \"method\": [\"Alibi_Proto\"],\n",
    "    \"Avg Time(s)\": [time_Alibi_proto],\n",
    "    \"Validity\": [valid_alibi_proto],\n",
    "    \"Sparsity\": [sparsity_alibi_proto],\n",
    "    \"Proximity_con\": [con_proximity_alibi_proto],\n",
    "    \"Proximity_cat\": [cat_proximity_alibi_proto],\n",
    "    \"Manifold\": [manifold_alibi_proto],\n",
    "    \"Avg CF count\": [cf_num_alibi_proto]\n",
    "}\n",
    "\n",
    "df_results_alibi_proto = pd.DataFrame(results_alibi_proto)\n",
    "df_results_alibi_proto = df_results_alibi_proto.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9e5857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_alibi_proto.to_csv('./results/Alibi_Proto_result_heart.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dice_XAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
