{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8a0ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from alibi.explainers import CounterfactualRLTabular, CounterfactualRL\n",
    "from alibi.datasets import fetch_adult\n",
    "from alibi.models.tensorflow import HeAE\n",
    "from alibi.models.tensorflow import Actor, Critic\n",
    "from alibi.models.tensorflow import ADULTEncoder, ADULTDecoder\n",
    "from alibi.explainers.cfrl_base import Callback\n",
    "from alibi.explainers.backends.cfrl_tabular import get_he_preprocessor, get_statistics, \\\n",
    "    get_conditional_vector, apply_category_mapping\n",
    "import random\n",
    "\n",
    "def set_seed(s=0):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45d79456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Optional, Tuple, Union\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from alibi.utils.data import Bunch\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "df = pd.read_csv('.\\\\pre_bank.csv')\n",
    "categorical_features = [\n",
    "    'job',\n",
    "    'marital',\n",
    "    'education',\n",
    "    'default',\n",
    "    'housing',\n",
    "    'loan',\n",
    "    'contact',\n",
    "    'month',\n",
    "    'poutcome'\n",
    "]\n",
    "df[categorical_features] = df[categorical_features].astype(str)\n",
    "\n",
    "\n",
    "def fetch_bank(\n",
    "    features_drop: Optional[list] = None, \n",
    "    return_X_y: bool = False, \n",
    "    categorical_features: Optional[list] = None\n",
    ") -> Union[Bunch, Tuple[np.ndarray, np.ndarray]]:\n",
    "    \n",
    "    raw_data = df\n",
    "    # get labels, features and drop unnecessary features\n",
    "    labels = (raw_data['y'] == 1).astype(int).values\n",
    "\n",
    "    if features_drop is None:\n",
    "        features_drop = []\n",
    "    features_drop = features_drop + ['y']\n",
    "\n",
    "    data = raw_data.drop(features_drop, axis=1)\n",
    "    features = list(data.columns)\n",
    "\n",
    "    # 关键部分：外部指定优先，否则自动推断\n",
    "    if categorical_features is None:\n",
    "        categorical_features = [f for f in features if data[f].dtype == 'O']\n",
    "\n",
    "    category_map = {}\n",
    "    for f in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        data_tmp = le.fit_transform(data[f].values)\n",
    "        data[f] = data_tmp\n",
    "        category_map[features.index(f)] = list(le.classes_)\n",
    "\n",
    "    # only return data values\n",
    "    data = data.values\n",
    "    target_names = [0, 1]\n",
    "\n",
    "    if return_X_y:\n",
    "        return data, labels\n",
    "\n",
    "    return Bunch(\n",
    "        data=data, \n",
    "        target=labels, \n",
    "        feature_names=features, \n",
    "        target_names=target_names, \n",
    "        category_map=category_map\n",
    "    )\n",
    "\n",
    "bank = fetch_bank(\n",
    "    categorical_features=categorical_features\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c7cd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ebd088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1️⃣ 划分类别型和数值型特征\n",
    "\n",
    "\n",
    "# Separate columns in numerical and categorical.\n",
    "categorical_names = [bank.feature_names[i] for i in bank.category_map.keys()]\n",
    "categorical_ids = list(bank.category_map.keys())\n",
    "\n",
    "numerical_names = [name for i, name in enumerate(bank.feature_names) if i not in bank.category_map.keys()]\n",
    "numerical_ids = [i for i in range(len(bank.feature_names)) if i not in bank.category_map.keys()]\n",
    "\n",
    "# Split data into train and test\n",
    "X, Y = bank.data, bank.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f061d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "# Define numerical standard scaler.\n",
    "num_transf = MinMaxScaler()\n",
    "\n",
    "# Define categorical one-hot encoder.\n",
    "cat_transf = OneHotEncoder(\n",
    "    categories=[range(len(x)) for x in bank.category_map.values()],\n",
    "    handle_unknown=\"ignore\"\n",
    ")\n",
    "\n",
    "# Define column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transf, numerical_ids),\n",
    "        (\"cat\", cat_transf, categorical_ids),\n",
    "    ],\n",
    "    sparse_threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef2d9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit preprocessor.\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# Preprocess train and test dataset.\n",
    "X_train_ohe = preprocessor.transform(X_train)\n",
    "X_test_ohe = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd8056ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "def build_simple_dnn():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(32, activation='relu', input_shape=(49,)))  # 输入31维特征\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "model = build_simple_dnn()\n",
    "model.load_weights('my_model_weights_bank.h5')   # 加载之前保存的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50f40e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08495279, 0.91504717],\n",
       "       [0.02794113, 0.97205895]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define prediction function.\n",
    "predictor = lambda x: model.predict(preprocessor.transform(x), verbose=0)\n",
    "\n",
    "predictor(X_test[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3c04846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Compute accuracy.\n",
    "acc = accuracy_score(y_true=Y_test, y_pred=predictor(X_test).argmax(axis=1))\n",
    "print(\"Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9da2457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'balance', 'day', 'duration', 'campaign']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e4312416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attribute types, required for datatype conversion.\n",
    "feature_types = {'age': int, 'balance': int, 'day': int, 'duration': int, 'campaign': int}\n",
    "\n",
    "# Define data preprocessor and inverse preprocessor. The invers preprocessor include datatype conversions.\n",
    "heae_preprocessor, heae_inv_preprocessor = get_he_preprocessor(X=X_train,\n",
    "                                                               feature_names=bank.feature_names,\n",
    "                                                               category_map=bank.category_map,\n",
    "                                                               feature_types=feature_types)\n",
    "\n",
    "# Define trainset\n",
    "trainset_input = heae_preprocessor(X_train).astype(np.float32)\n",
    "trainset_outputs = {\n",
    "    \"output_1\": trainset_input[:, :len(numerical_ids)]\n",
    "}\n",
    "\n",
    "for i, cat_id in enumerate(categorical_ids):\n",
    "    trainset_outputs.update({\n",
    "        f\"output_{i+2}\": X_train[:, cat_id]\n",
    "    })\n",
    "    \n",
    "trainset = tf.data.Dataset.from_tensor_slices((trainset_input, trainset_outputs))\n",
    "trainset = trainset.shuffle(1024).batch(32, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8865daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define autoencoder path and create dir if it doesn't exist.\n",
    "heae_path = os.path.join(\"tensorflow_bank\", \"ADULT_autoencoder\")\n",
    "if not os.path.exists(heae_path):\n",
    "    os.makedirs(heae_path)\n",
    "\n",
    "# Define constants.\n",
    "EPOCHS = 50             # epochs to train the autoencoder\n",
    "HIDDEN_DIM = 128         # hidden dimension of the autoencoder\n",
    "LATENT_DIM = 20          # define latent dimension\n",
    "\n",
    "# Define output dimensions.\n",
    "OUTPUT_DIMS = [len(numerical_ids)]\n",
    "OUTPUT_DIMS += [len(bank.category_map[cat_id]) for cat_id in categorical_ids]\n",
    "\n",
    "# Define the heterogeneous auto-encoder.\n",
    "heae = HeAE(encoder=ADULTEncoder(hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM),\n",
    "            decoder=ADULTDecoder(hidden_dim=HIDDEN_DIM, output_dims=OUTPUT_DIMS))\n",
    "\n",
    "# Define loss functions.\n",
    "he_loss = [keras.losses.MeanSquaredError()]\n",
    "he_loss_weights = [1.]\n",
    "\n",
    "# Add categorical losses.\n",
    "for i in range(len(categorical_names)):\n",
    "    he_loss.append(keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "    he_loss_weights.append(1./len(categorical_names))\n",
    "\n",
    "# Define metrics.\n",
    "metrics = {}\n",
    "for i, cat_name in enumerate(categorical_names):\n",
    "    metrics.update({f\"output_{i+2}\": keras.metrics.SparseCategoricalAccuracy()})\n",
    "    \n",
    "# Compile model.\n",
    "heae.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "             loss=he_loss,\n",
    "             loss_weights=he_loss_weights,\n",
    "             metrics=metrics)\n",
    "\n",
    "if len(os.listdir(heae_path)) == 0:\n",
    "    # Fit and save autoencoder.\n",
    "    heae.fit(trainset, epochs=EPOCHS)\n",
    "    heae.save(heae_path, save_format=\"tf\")\n",
    "else:\n",
    "    # Load the model.\n",
    "    heae = keras.models.load_model(heae_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8481fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数0: adult_encoder/dense_2/kernel:0, 形状: (49, 128)\n",
      "[[ 0.16955987 -0.02945541  0.00368213 ... -0.00764013 -0.0503218\n",
      "  -0.08211114]\n",
      " [ 0.00210219  0.01771733 -0.05446194 ...  0.01902988  0.22840506\n",
      "   0.02035353]\n",
      " [-0.03494316 -0.01455933 -0.03574897 ... -0.00426898 -0.1830821\n",
      "   0.11857364]\n",
      " ...\n",
      " [ 0.06157698  0.09224897  0.15947539 ...  0.11723     0.04373055\n",
      "   0.15644035]\n",
      " [ 0.1731051   0.06974736  0.04557892 ...  0.06204503  0.06142191\n",
      "  -0.04512652]\n",
      " [ 0.19792186  0.12175795  0.19045521 ...  0.03161228  0.13781269\n",
      "   0.08231993]]\n",
      "参数1: adult_encoder/dense_2/bias:0, 形状: (128,)\n",
      "[ 0.07128768  0.01407799  0.07354799  0.02693616  0.02506502  0.02519572\n",
      " -0.02094448 -0.00422953  0.09502146  0.09082495 -0.03308912  0.04188995\n",
      "  0.06604271  0.00718864 -0.03178789 -0.01368643  0.0624559  -0.01332409\n",
      " -0.00674581 -0.05733289  0.04470127  0.01302228  0.03336751  0.00172157\n",
      "  0.03690324  0.04314944 -0.02711393  0.03699955  0.03870979 -0.01512121\n",
      "  0.08398003  0.02924956 -0.05123693  0.00955863  0.00443862  0.06909304\n",
      "  0.08211531  0.08210209 -0.01367244  0.09305735  0.05578132  0.02624648\n",
      " -0.00686221  0.0091137   0.10108722  0.00152472  0.03648224  0.05314376\n",
      " -0.02017511  0.05944116 -0.03400567  0.02163595 -0.03979199 -0.2753315\n",
      "  0.01887916 -0.13900475 -0.02746358  0.07199442 -0.0117884   0.00171801\n",
      "  0.06850324 -0.02386118 -0.04014822  0.0295349   0.00756103  0.05395926\n",
      "  0.05966608  0.07286365  0.01756422 -0.05815943  0.01496742 -0.00197541\n",
      "  0.04314708 -0.00549386 -0.02274163 -0.03829471  0.04734271  0.00748562\n",
      " -0.05333487  0.01206158  0.04507711  0.03218447 -0.03738239  0.00200316\n",
      "  0.0496073   0.03318164  0.06740013 -0.08838768  0.01915583  0.00716703\n",
      "  0.02195732  0.04505576 -0.01334098  0.06522924 -0.04902849  0.03525916\n",
      "  0.04318576  0.03400893 -0.01352524  0.06479401  0.06353567  0.08931112\n",
      " -0.01770462  0.0053569  -0.00269834 -0.00363122  0.00434519  0.04582328\n",
      "  0.09554639  0.02800261 -0.01353538  0.02890856 -0.04496415 -0.00532623\n",
      "  0.03627244  0.06671768 -0.02650931 -0.04025278  0.05679696 -0.22327298\n",
      " -0.00918622  0.04515566  0.03263573  0.04183465  0.04778822 -0.01734456\n",
      "  0.06191922  0.00441176]\n",
      "参数2: adult_encoder/dense_3/kernel:0, 形状: (128, 20)\n",
      "[[-0.19289018  0.11305305  0.02457309 ...  0.22433618  0.14665318\n",
      "   0.06353584]\n",
      " [-0.04178217  0.07635024 -0.00332859 ...  0.03139037  0.10833848\n",
      "  -0.03548721]\n",
      " [-0.16515037  0.13371724  0.10093629 ... -0.00523498 -0.18413216\n",
      "   0.15429395]\n",
      " ...\n",
      " [ 0.00303961  0.031172   -0.13263828 ...  0.12716456  0.07618078\n",
      "   0.18567456]\n",
      " [-0.07409259  0.14741158  0.04007977 ... -0.1321195  -0.10502834\n",
      "  -0.0804973 ]\n",
      " [ 0.12154274 -0.10597062  0.03038112 ...  0.04844492 -0.17173143\n",
      "   0.13244356]]\n",
      "参数3: adult_encoder/dense_3/bias:0, 形状: (20,)\n",
      "[ 0.03740242  0.00980724 -0.03618835 -0.0182062   0.03371392  0.02832189\n",
      " -0.039608   -0.04106206 -0.01020513 -0.0141671  -0.02143645  0.01371693\n",
      "  0.0031367  -0.00683303  0.00211389 -0.03185136 -0.04279844 -0.02920772\n",
      " -0.04098431 -0.0109062 ]\n"
     ]
    }
   ],
   "source": [
    "# 输出encoder的全部权重（包括隐藏层）\n",
    "for i, weight in enumerate(heae.encoder.weights):\n",
    "    print(f\"参数{i}: {weight.name}, 形状: {weight.shape}\")\n",
    "    print(weight.numpy())  # 打印具体数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9d0db089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "COEFF_SPARSITY = 0.5               # sparisty coefficient\n",
    "COEFF_CONSISTENCY = 0.5            # consisteny coefficient\n",
    "TRAIN_STEPS = 10000              # number of training steps -> consider increasing the number of steps\n",
    "BATCH_SIZE = 100                   # batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d352c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "class RewardCallback(Callback):\n",
    "    def __call__(self,\n",
    "                 step: int, \n",
    "                 update: int, \n",
    "                 model: CounterfactualRL,\n",
    "                 sample: Dict[str, np.ndarray],\n",
    "                 losses: Dict[str, float]):\n",
    "        \n",
    "        if (step + update) % 100 != 0:\n",
    "            return\n",
    "        \n",
    "        # get the counterfactual and target\n",
    "        Y_t = sample[\"Y_t\"]\n",
    "        X_cf = model.params[\"decoder_inv_preprocessor\"](sample[\"X_cf\"])\n",
    "        \n",
    "        # get prediction label\n",
    "        Y_m_cf = predictor(X_cf)\n",
    "        \n",
    "        # compute reward\n",
    "        reward = np.mean(model.params[\"reward_func\"](Y_m_cf, Y_t))\n",
    "        wandb.log({\"reward\": reward})\n",
    "\n",
    "class LossCallback(Callback):\n",
    "    def __call__(self,\n",
    "                 step: int, \n",
    "                 update: int, \n",
    "                 model: CounterfactualRL,\n",
    "                 sample: Dict[str, np.ndarray],\n",
    "                 losses: Dict[str, float]):\n",
    "        # Log training losses.\n",
    "        if (step + update) % 100 == 0:\n",
    "            wandb.log(losses)\n",
    "\n",
    "class TablesCallback(Callback):\n",
    "    def __call__(self,\n",
    "                 step: int, \n",
    "                 update: int, \n",
    "                 model: CounterfactualRL,\n",
    "                 sample: Dict[str, np.ndarray],\n",
    "                 losses: Dict[str, float]):\n",
    "        # Log every 1000 steps\n",
    "        if step % 1000 != 0:\n",
    "            return\n",
    "        \n",
    "        # Define number of samples to be displayed.\n",
    "        NUM_SAMPLES = 5\n",
    "        \n",
    "        X = heae_inv_preprocessor(sample[\"X\"][:NUM_SAMPLES])        # input instance\n",
    "        X_cf = heae_inv_preprocessor(sample[\"X_cf\"][:NUM_SAMPLES])  # counterfactual\n",
    "        \n",
    "        Y_m = np.argmax(sample[\"Y_m\"][:NUM_SAMPLES], axis=1).astype(int).reshape(-1, 1) # input labels\n",
    "        Y_t = np.argmax(sample[\"Y_t\"][:NUM_SAMPLES], axis=1).astype(int).reshape(-1, 1) # target labels\n",
    "        Y_m_cf = np.argmax(predictor(X_cf), axis=1).astype(int).reshape(-1, 1)          # counterfactual labels\n",
    "        \n",
    "        # Define feature names and category map for input.\n",
    "        feature_names = bank.feature_names + [\"Label\"]\n",
    "        category_map = deepcopy(bank.category_map)\n",
    "        category_map.update({feature_names.index(\"Label\"): bank.target_names})\n",
    "        \n",
    "        # Construct input array.\n",
    "        inputs = np.concatenate([X, Y_m], axis=1)\n",
    "        inputs = pd.DataFrame(apply_category_mapping(inputs, category_map),\n",
    "                              columns=feature_names)\n",
    "        \n",
    "        # Define feature names and category map for counterfactual output.\n",
    "        feature_names += [\"y\"]\n",
    "        category_map.update({feature_names.index(\"y\"): bank.target_names})\n",
    "        \n",
    "        # Construct output array.\n",
    "        outputs = np.concatenate([X_cf, Y_m_cf, Y_t], axis=1)\n",
    "        outputs = pd.DataFrame(apply_category_mapping(outputs, category_map),\n",
    "                               columns=feature_names)\n",
    "        \n",
    "        # Log table.\n",
    "        wandb.log({\n",
    "            \"Input\": wandb.Table(dataframe=inputs),\n",
    "            \"Output\": wandb.Table(dataframe=outputs)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69cad1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▇█▃▂▁▂▃▂▂▂</td></tr><tr><td>consistency_loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>critic_loss</td><td>▇█▆▆▄▃▃▂▁▁</td></tr><tr><td>reward</td><td>▁▁▇▇███▇██</td></tr><tr><td>sparsity_cat_loss</td><td>█▇▇▅▄▄▅▄▄▁</td></tr><tr><td>sparsity_num_loss</td><td>█▄▄▃▃▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>-0.98851</td></tr><tr><td>consistency_loss</td><td>0.1016</td></tr><tr><td>critic_loss</td><td>0.04133</td></tr><tr><td>reward</td><td>0.96</td></tr><tr><td>sparsity_cat_loss</td><td>0.38</td></tr><tr><td>sparsity_num_loss</td><td>0.23529</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grateful-breeze-29</strong> at: <a href='https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning/runs/2n45y9ep' target=\"_blank\">https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning/runs/2n45y9ep</a><br> View project at: <a href='https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning' target=\"_blank\">https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250824_015528-2n45y9ep\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\Graduation_Project\\CFs_Project\\wandb\\run-20250824_015717-j2y1yz31</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning/runs/j2y1yz31' target=\"_blank\">zany-night-30</a></strong> to <a href='https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning' target=\"_blank\">https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning/runs/j2y1yz31' target=\"_blank\">https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning/runs/j2y1yz31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define immutable features.\n",
    "immutable_features = ['sex']\n",
    "\n",
    "# Define ranges. This means that the `Age` feature can not decrease.\n",
    "ranges = {'age': [0.0, 1.0]}\n",
    "\n",
    "# Initialize wandb.\n",
    "wandb_project = \"Adult Census Counterfactual with Reinforcement Learning\"\n",
    "wandb.init(project=wandb_project)\n",
    "\n",
    "explainer = CounterfactualRLTabular(predictor=predictor,\n",
    "                                    encoder=heae.encoder,\n",
    "                                    decoder=heae.decoder,\n",
    "                                    latent_dim=LATENT_DIM,\n",
    "                                    encoder_preprocessor=heae_preprocessor,\n",
    "                                    decoder_inv_preprocessor=heae_inv_preprocessor,\n",
    "                                    coeff_sparsity=COEFF_SPARSITY,\n",
    "                                    coeff_consistency=COEFF_CONSISTENCY,\n",
    "                                    category_map=bank.category_map,\n",
    "                                    feature_names=bank.feature_names,\n",
    "                                    immutable_features=immutable_features,\n",
    "                                    ranges=ranges,\n",
    "                                    train_steps=TRAIN_STEPS,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    backend=\"tensorflow\",\n",
    "                                    callbacks=[LossCallback(), RewardCallback(), TablesCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa3042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▇█▃▂▁▂▃▂▂▂</td></tr><tr><td>consistency_loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>critic_loss</td><td>▇█▆▆▄▃▃▂▁▁</td></tr><tr><td>reward</td><td>▁▁▇▇███▇██</td></tr><tr><td>sparsity_cat_loss</td><td>█▇▇▅▄▄▅▄▄▁</td></tr><tr><td>sparsity_num_loss</td><td>█▄▄▃▃▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>-0.98851</td></tr><tr><td>consistency_loss</td><td>0.1016</td></tr><tr><td>critic_loss</td><td>0.04133</td></tr><tr><td>reward</td><td>0.96</td></tr><tr><td>sparsity_cat_loss</td><td>0.38</td></tr><tr><td>sparsity_num_loss</td><td>0.23529</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zany-night-30</strong> at: <a href='https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning/runs/j2y1yz31' target=\"_blank\">https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning/runs/j2y1yz31</a><br> View project at: <a href='https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning' target=\"_blank\">https://wandb.ai/a1227872681-university-of-bristol/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250824_015717-j2y1yz31\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1000/10000 [01:01<09:15, 16.20it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\a1227\\\\AppData\\\\Local\\\\Temp\\\\tmpn0qz8frrwandb-media\\\\p8kgmdmh.table.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffline\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# 改成 offline 模式\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Fit the explainer.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Close wandb.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\alibi\\explainers\\cfrl_tabular.py:279\u001b[0m, in \u001b[0;36mCounterfactualRLTabular.fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(X)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# call base class fit\u001b[39;00m\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\alibi\\explainers\\cfrl_base.py:746\u001b[0m, in \u001b[0;36mCounterfactualRL.fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    744\u001b[0m             \u001b[38;5;66;03m# Call all callbacks.\u001b[39;00m\n\u001b[0;32m    745\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 746\u001b[0m                 \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "Cell \u001b[1;32mIn[64], line 78\u001b[0m, in \u001b[0;36mTablesCallback.__call__\u001b[1;34m(self, step, update, model, sample, losses)\u001b[0m\n\u001b[0;32m     74\u001b[0m outputs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(apply_category_mapping(outputs, category_map),\n\u001b[0;32m     75\u001b[0m                        columns\u001b[38;5;241m=\u001b[39mfeature_names)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Log table.\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:406\u001b[0m, in \u001b[0;36m_log_to_run.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    403\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attach_id\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wb_logging\u001b[38;5;241m.\u001b[39mlog_to_run(run_id):\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:503\u001b[0m, in \u001b[0;36m_noop_if_forked_with_no_service.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    500\u001b[0m init_pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pid\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_using_service \u001b[38;5;129;01mor\u001b[39;00m init_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid():\n\u001b[1;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    505\u001b[0m message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` ignored (called from pid=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mgetpid()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `init` called from pid=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minit_pid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m See: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_registry\u001b[38;5;241m.\u001b[39murl(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultiprocess\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m )\n\u001b[0;32m    511\u001b[0m \u001b[38;5;66;03m# This attribute may not exist because it is not included in the run's\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# pickled state.\u001b[39;00m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:464\u001b[0m, in \u001b[0;36m_raise_if_finished.<locals>.wrapper_fn\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m: Run, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_finished\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 464\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    466\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is finished. The call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please make sure that you are using an active run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    470\u001b[0m     )\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(message)\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:451\u001b[0m, in \u001b[0;36m_attach.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m         _is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:2071\u001b[0m, in \u001b[0;36mRun.log\u001b[1;34m(self, data, step, commit, sync)\u001b[0m\n\u001b[0;32m   2064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39m_shared \u001b[38;5;129;01mand\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2065\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mtermwarn(\n\u001b[0;32m   2066\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn shared mode, the use of `wandb.log` with the step argument is not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2067\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand will be ignored. Please refer to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_registry\u001b[38;5;241m.\u001b[39murl(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefine-metric\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2068\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon how to customize your x-axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2069\u001b[0m         repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2070\u001b[0m     )\n\u001b[1;32m-> 2071\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:1783\u001b[0m, in \u001b[0;36mRun._log\u001b[1;34m(self, data, step, commit)\u001b[0m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey values passed to `wandb.log` must be strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1783\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_history_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetpid() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pid \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attached:\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:406\u001b[0m, in \u001b[0;36m_log_to_run.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    403\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attach_id\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wb_logging\u001b[38;5;241m.\u001b[39mlog_to_run(run_id):\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:1610\u001b[0m, in \u001b[0;36mRun._partial_history_callback\u001b[1;34m(self, data, step, commit)\u001b[0m\n\u001b[0;32m   1607\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialize_custom_charts(data)\n\u001b[0;32m   1609\u001b[0m not_using_tensorboard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(wandb\u001b[38;5;241m.\u001b[39mpatched[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1610\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_partial_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpublish_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnot_using_tensorboard\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py:673\u001b[0m, in \u001b[0;36mInterfaceBase.publish_partial_history\u001b[1;34m(self, run, data, user_step, step, flush, publish_step)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_partial_history\u001b[39m(\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    666\u001b[0m     run: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    671\u001b[0m     publish_step: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    672\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhistory_dict_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_copy_err\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    674\u001b[0m     data\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;66;03m# add timestamp to the history request, if not already present\u001b[39;00m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;66;03m# the timestamp might come from the tensorboard log logic\u001b[39;00m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\data_types\\utils.py:54\u001b[0m, in \u001b[0;36mhistory_dict_to_json\u001b[1;34m(run, payload, step, ignore_copy_err)\u001b[0m\n\u001b[0;32m     50\u001b[0m         payload[key] \u001b[38;5;241m=\u001b[39m history_dict_to_json(\n\u001b[0;32m     51\u001b[0m             run, val, step\u001b[38;5;241m=\u001b[39mstep, ignore_copy_err\u001b[38;5;241m=\u001b[39mignore_copy_err\n\u001b[0;32m     52\u001b[0m         )\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m         payload[key] \u001b[38;5;241m=\u001b[39m \u001b[43mval_to_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_copy_err\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_copy_err\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m payload\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\data_types\\utils.py:162\u001b[0m, in \u001b[0;36mval_to_json\u001b[1;34m(run, key, val, namespace, ignore_copy_err)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;66;03m# Partitioned tables and joined tables do not support being bound to runs.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    159\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(val, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_log_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39m_log_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartitioned-table\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoined-table\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    161\u001b[0m         ):\n\u001b[1;32m--> 162\u001b[0m             \u001b[43mval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_to_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val\u001b[38;5;241m.\u001b[39mto_json(run)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m converted\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\site-packages\\wandb\\sdk\\data_types\\table.py:509\u001b[0m, in \u001b[0;36mTable.bind_to_run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    507\u001b[0m tmp_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MEDIA_TMP\u001b[38;5;241m.\u001b[39mname, runid\u001b[38;5;241m.\u001b[39mgenerate_id() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.table.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    508\u001b[0m data \u001b[38;5;241m=\u001b[39m _numpy_arrays_to_lists(data)\n\u001b[1;32m--> 509\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    510\u001b[0m     util\u001b[38;5;241m.\u001b[39mjson_dump_safer(data, fp)\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_file(tmp_path, is_tmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.table.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\dice_XAI\\lib\\codecs.py:905\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    902\u001b[0m    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;66;03m# Force opening of the file in binary mode\u001b[39;00m\n\u001b[0;32m    904\u001b[0m     mode \u001b[38;5;241m=\u001b[39m mode \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 905\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\a1227\\\\AppData\\\\Local\\\\Temp\\\\tmpn0qz8frrwandb-media\\\\p8kgmdmh.table.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fit the explainer.\n",
    "explainer = explainer.fit(X=X_train)\n",
    "\n",
    "# Close wandb.\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate counterfactual instances.\n",
    "sample_num = 5543\n",
    "X = X_train[sample_num].reshape(1, -1)\n",
    "Y_t = np.array([1 - Y_train[sample_num]])\n",
    "C = [{\n",
    "'age': [0, 20]       # 限定 age 在 0~70\n",
    "}]\n",
    "explanation = explainer.explain(X=X, Y_t=Y_t, C=C, diversity=True, num_samples=4, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf19e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cf = explanation.data['cf']['X']\n",
    "predictor(X_cf).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c643fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat labels to the original instances.\n",
    "orig = np.concatenate(\n",
    "    [explanation.data['orig']['X'], explanation.data['orig']['class']],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Concat labels to the counterfactual instances.\n",
    "cf = np.concatenate(\n",
    "    [X_cf, explanation.data['cf']['class']],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Define new feature names and category map by including the label.\n",
    "feature_names = bank.feature_names + [\"y\"]\n",
    "category_map = deepcopy(bank.category_map)\n",
    "category_map.update({feature_names.index(\"y\"): bank.target_names})\n",
    "\n",
    "# Replace label encodings with strings.\n",
    "orig_pd = pd.DataFrame(\n",
    "    apply_category_mapping(orig, category_map),\n",
    "    columns=feature_names\n",
    ")\n",
    "\n",
    "cf_pd = pd.DataFrame(\n",
    "    apply_category_mapping(cf, category_map),\n",
    "    columns=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86eb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>177</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>may</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age         job  marital  education default balance housing loan   contact  \\\n",
       "0  47  management  married  secondary      no     177     yes   no  cellular   \n",
       "\n",
       "  day month duration campaign poutcome  y  \n",
       "0  14   may       95        3  unknown  0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_pd.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e8137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>516</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>mar</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>636</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>mar</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>652</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>jun</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>453</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>aug</td>\n",
       "      <td>283</td>\n",
       "      <td>3</td>\n",
       "      <td>failure</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age         job  marital  education default balance housing loan   contact  \\\n",
       "0  47  management  married  secondary      no     516     yes   no  cellular   \n",
       "1  47  management  married  secondary      no     636     yes   no  cellular   \n",
       "2  47  management  married  secondary      no     652     yes   no  cellular   \n",
       "3  47  management  married   tertiary      no     453     yes   no  cellular   \n",
       "\n",
       "  day month duration campaign poutcome  y  \n",
       "0  14   mar       83        3  success  1  \n",
       "1  14   mar       94        3  success  1  \n",
       "2  14   jun      105        3  success  1  \n",
       "3  14   aug      283        3  failure  1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cf_pd.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ba273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 10.33it/s]\n",
      "1it [00:00, 10.30it/s]\n",
      "1it [00:00, 11.43it/s]\n",
      "1it [00:00, 10.27it/s]\n",
      "1it [00:00,  9.80it/s]\n",
      "1it [00:00,  9.61it/s]\n",
      "1it [00:00, 11.06it/s]\n",
      "1it [00:00, 11.32it/s]\n",
      "1it [00:00, 10.58it/s]\n",
      "1it [00:00, 10.12it/s]\n",
      "1it [00:00, 10.99it/s]\n",
      "1it [00:00, 11.23it/s]\n",
      "1it [00:00, 11.31it/s]\n",
      "1it [00:00, 11.91it/s]\n",
      "1it [00:00, 10.69it/s]\n",
      "1it [00:00,  9.74it/s]\n",
      "1it [00:00, 10.30it/s]\n",
      "1it [00:00,  9.56it/s]\n",
      "1it [00:00,  9.75it/s]\n",
      "1it [00:00, 10.31it/s]\n",
      "1it [00:00, 10.73it/s]\n",
      "1it [00:00,  8.37it/s]\n",
      "1it [00:00,  9.16it/s]\n",
      "1it [00:00,  9.38it/s]\n",
      "1it [00:00,  9.83it/s]\n",
      "1it [00:00, 10.77it/s]\n",
      "1it [00:00, 11.91it/s]\n",
      "1it [00:00, 11.23it/s]\n",
      "1it [00:00, 10.25it/s]\n",
      "1it [00:00, 10.66it/s]\n",
      "1it [00:00, 10.47it/s]\n",
      "1it [00:00, 10.39it/s]\n",
      "1it [00:00, 11.34it/s]\n",
      "1it [00:00, 11.13it/s]\n",
      "1it [00:00, 10.81it/s]\n",
      "1it [00:00, 10.41it/s]\n",
      "1it [00:00,  7.82it/s]\n",
      "1it [00:00,  5.93it/s]\n",
      "1it [00:00,  6.00it/s]\n",
      "1it [00:00,  6.28it/s]\n",
      "1it [00:00,  6.10it/s]\n",
      "1it [00:00,  6.96it/s]\n",
      "1it [00:00,  6.91it/s]\n",
      "1it [00:00,  7.05it/s]\n",
      "1it [00:00,  7.39it/s]\n",
      "1it [00:00,  7.16it/s]\n",
      "1it [00:00,  6.95it/s]\n",
      "1it [00:00,  6.63it/s]\n",
      "1it [00:00,  6.50it/s]\n",
      "1it [00:00,  7.06it/s]\n",
      "1it [00:00,  5.90it/s]\n",
      "1it [00:00,  6.29it/s]\n",
      "1it [00:00,  7.27it/s]\n",
      "1it [00:00,  6.43it/s]\n",
      "1it [00:00,  6.26it/s]\n",
      "1it [00:00,  6.03it/s]\n",
      "1it [00:00,  6.38it/s]\n",
      "1it [00:00,  5.69it/s]\n",
      "1it [00:00,  6.89it/s]\n",
      "1it [00:00,  6.17it/s]\n",
      "1it [00:00,  6.66it/s]\n",
      "1it [00:00,  6.73it/s]\n",
      "1it [00:00,  6.45it/s]\n",
      "1it [00:00,  8.22it/s]\n",
      "1it [00:00,  9.58it/s]\n",
      "1it [00:00,  8.50it/s]\n",
      "1it [00:00,  9.54it/s]\n",
      "1it [00:00,  8.79it/s]\n",
      "1it [00:00, 10.89it/s]\n",
      "1it [00:00, 10.78it/s]\n",
      "1it [00:00,  8.54it/s]\n",
      "1it [00:00, 10.50it/s]\n",
      "1it [00:00,  9.88it/s]\n",
      "1it [00:00, 10.53it/s]\n",
      "1it [00:00, 11.30it/s]\n",
      "1it [00:00, 10.78it/s]\n",
      "1it [00:00,  9.67it/s]\n",
      "1it [00:00, 10.27it/s]\n",
      "1it [00:00,  9.18it/s]\n",
      "1it [00:00,  9.61it/s]\n",
      "1it [00:00,  7.45it/s]\n",
      "1it [00:00, 12.09it/s]\n",
      "1it [00:00, 12.38it/s]\n",
      "1it [00:00,  9.61it/s]\n",
      "1it [00:00, 11.99it/s]\n",
      "1it [00:00, 10.47it/s]\n",
      "1it [00:00,  9.66it/s]\n",
      "1it [00:00,  9.95it/s]\n",
      "1it [00:00, 11.67it/s]\n",
      "1it [00:00, 12.49it/s]\n",
      "1it [00:00, 11.00it/s]\n",
      "1it [00:00,  8.36it/s]\n",
      "1it [00:00, 10.33it/s]\n",
      "1it [00:00, 12.16it/s]\n",
      "1it [00:00, 15.92it/s]\n",
      "1it [00:00, 11.81it/s]\n",
      "1it [00:00, 15.12it/s]\n",
      "1it [00:00, 10.95it/s]\n",
      "1it [00:00, 15.36it/s]\n",
      "1it [00:00, 12.16it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='.*has feature names.*')\n",
    "import time\n",
    "\n",
    "cfs = []\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i, X_test_i in enumerate(X_test[:100]):\n",
    "    X = X_test_i.reshape(1, -1)\n",
    "    Y_t = 1 - predictor(X).argmax(axis=1)\n",
    "    C = [{\n",
    "    'age': [0, 20]       # 限定 age 在 0~70\n",
    "    }]\n",
    "    explanation = explainer.explain(X=X, Y_t=Y_t, C=C, diversity=True, num_samples=4, batch_size=10)\n",
    "    \n",
    "    # Concat labels to the original instances.\n",
    "    orig = np.concatenate(\n",
    "        [explanation.data['orig']['X'], explanation.data['orig']['class']],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Concat labels to the counterfactual instances.\n",
    "    cf = np.concatenate(\n",
    "        [explanation.data['cf']['X'], explanation.data['cf']['class']],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Define new feature names and category map by including the label.\n",
    "    feature_names = bank.feature_names + [\"y\"]\n",
    "    category_map = deepcopy(bank.category_map)\n",
    "    category_map.update({feature_names.index(\"y\"): bank.target_names})\n",
    "\n",
    "    # Replace label encodings with strings.\n",
    "    orig_pd = pd.DataFrame(\n",
    "        apply_category_mapping(orig, category_map),\n",
    "        columns=feature_names\n",
    "    )\n",
    "\n",
    "    cf_pd = pd.DataFrame(\n",
    "        apply_category_mapping(cf, category_map),\n",
    "        columns=feature_names\n",
    "    )\n",
    "    cfs.append((\n",
    "        orig_pd, cf_pd\n",
    "    ))\n",
    "end = time.time()\n",
    "\n",
    "time_Alibi_cfrl = (end - start)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa831ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 映射\n",
    "def custom_label_encoder(feature_names, df):\n",
    "    arr = []\n",
    "    for _, row in df.iterrows():\n",
    "        encoded_row = []\n",
    "        for i, f in enumerate(feature_names):\n",
    "            if i in category_map:\n",
    "                val = row[f]\n",
    "                idx = category_map[i].index(val)\n",
    "                encoded_row.append(idx)\n",
    "            else:\n",
    "                encoded_row.append(float(row[f]))\n",
    "        arr.append(encoded_row)\n",
    "    # 返回二维 array，类型 float32\n",
    "    return np.array(arr)[:, :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_count = 0\n",
    "total = 0\n",
    "for X_org, X_cfs in cfs:\n",
    "    # 预测原始类别（X_org必须二维）\n",
    "    y_true = model.predict(preprocessor.transform(custom_label_encoder(feature_names, X_org)), \n",
    "                           verbose=0).argmax(axis=1)[0]\n",
    "    # 预测反事实类别（批量）\n",
    "    y_cfs = model.predict(preprocessor.transform(custom_label_encoder(feature_names, X_cfs)), \n",
    "                          verbose=0).argmax(axis=1)\n",
    "    # 统计类别发生变化的样本数\n",
    "    valid_count += np.sum(y_cfs != y_true)\n",
    "    total += len(y_cfs)\n",
    "valid_alibi_cfrl = (valid_count / total if total > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from XAI_metrics import calc_sparsity, calc_continuous_proximity, \\\n",
    "    calc_categorical_proximity, calc_manifold_distance, calc_cf_num\n",
    "\n",
    "\n",
    "sparsity_alibi_cfrl = calc_sparsity(cfs, categorical_features)\n",
    "con_proximity_alibi_cfrl = calc_continuous_proximity(cfs, numerical_names)\n",
    "cat_proximity_alibi_cfrl = calc_categorical_proximity(cfs, categorical_features)\n",
    "manifold_alibi_cfrl = calc_manifold_distance(cfs, df, categorical_features)\n",
    "cf_num_alibi_cfrl = calc_cf_num(cfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305176fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>Avg Time(s)</th>\n",
       "      <th>Validity</th>\n",
       "      <th>Sparsity</th>\n",
       "      <th>Proximity_con</th>\n",
       "      <th>Proximity_cat</th>\n",
       "      <th>Manifold</th>\n",
       "      <th>Avg CF count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alibi_CFRL</td>\n",
       "      <td>0.260404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391281</td>\n",
       "      <td>0.805354</td>\n",
       "      <td>0.188056</td>\n",
       "      <td>21.747942</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       method  Avg Time(s)  Validity  Sparsity  Proximity_con  Proximity_cat  \\\n",
       "0  Alibi_CFRL     0.260404       1.0  0.391281       0.805354       0.188056   \n",
       "\n",
       "    Manifold  Avg CF count  \n",
       "0  21.747942           4.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_alibi_cfrl = {\n",
    "    \"method\": [\"Alibi_CFRL\"],\n",
    "    \"Avg Time(s)\": [time_Alibi_cfrl],\n",
    "    \"Validity\": [valid_alibi_cfrl],\n",
    "    \"Sparsity\": [sparsity_alibi_cfrl],\n",
    "    \"Proximity_con\": [con_proximity_alibi_cfrl],\n",
    "    \"Proximity_cat\": [cat_proximity_alibi_cfrl],\n",
    "    \"Manifold\": [manifold_alibi_cfrl],\n",
    "    \"Avg CF count\": [cf_num_alibi_cfrl]\n",
    "}\n",
    "\n",
    "df_results_alibi_cfrl = pd.DataFrame(results_alibi_cfrl)\n",
    "df_results_alibi_cfrl = df_results_alibi_cfrl.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bf17c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_results_alibi_cfrl.to_csv('./results/Alibi_CFRL_result_bank.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dice_XAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
